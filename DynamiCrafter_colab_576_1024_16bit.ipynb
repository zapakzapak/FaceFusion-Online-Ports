{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zapakzapak/FaceFusion-Online-Ports/blob/main/DynamiCrafter_colab_576_1024_16bit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6845a910-8fcd-4993-ad2e-482d49fa7e0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into '/content/DynamiCrafter-hf'...\n",
            "remote: Enumerating objects: 192, done.\u001b[K\n",
            "remote: Counting objects: 100% (192/192), done.\u001b[K\n",
            "remote: Compressing objects: 100% (129/129), done.\u001b[K\n",
            "remote: Total 192 (delta 62), reused 187 (delta 60), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (192/192), 8.35 MiB | 18.71 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n",
            "/content/DynamiCrafter-hf\n",
            "Downloading model checkpoint...\n",
            "Attempting download from: https://huggingface.co/Doubiiu/DynamiCrafter/resolve/main/checkpoints/dynamicrafter_1024_v1/model.ckpt\n",
            "Download failed or file too small. Trying next mirror...\n",
            "Attempting download from: https://huggingface.co/camenduru/DynamiCrafter/resolve/main/dynamicrafter_1024_v1.ckpt\n",
            "Download failed or file too small. Trying next mirror...\n",
            "Attempting download from: https://huggingface.co/vdo/DynamiCrafter/resolve/main/dynamicrafter_1024_v1.ckpt\n",
            "Download failed or file too small. Trying next mirror...\n",
            "Attempting download from: https://huggingface.co/checkpoints/DynamiCrafter/resolve/main/model.ckpt\n",
            "Download failed or file too small. Trying next mirror...\n",
            "CRITICAL ERROR: Could not download model from any mirror. Please check internet connection or HF availability.\n",
            "Patching app.py...\n",
            "VAE Patch injected successfully.\n",
            "Starting application...\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://16bbe9970402b368cd.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "model.ckpt: 100% 10.4G/10.4G [00:28<00:00, 360MB/s]\n",
            "AE working on z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "2025-11-23 19:37:25.107097: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-23 19:37:25.124730: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763926645.147402   21952 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763926645.154633   21952 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763926645.173327   21952 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763926645.173357   21952 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763926645.173360   21952 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763926645.173363   21952 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-23 19:37:25.179336: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            ">>> model checkpoint loaded.\n",
            "Applying VAE Patch (Float32)...\n",
            "Seed set to 123\n",
            "start: TURNING TOWARDS CAMERA AND DO YOGA POSE 2025-11-23 19:38:02\n",
            "AE working on z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            ">>> model checkpoint loaded.\n",
            "Applying VAE Patch (Float32)...\n",
            "Seed set to 123\n",
            "start: SMILING 2025-11-23 19:43:25\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import re\n",
        "import sys\n",
        "import types\n",
        "import subprocess\n",
        "\n",
        "# 1. CLEANUP\n",
        "# Remove existing folder to ensure clean install\n",
        "if os.path.exists('/content/DynamiCrafter-hf'):\n",
        "    shutil.rmtree('/content/DynamiCrafter-hf')\n",
        "\n",
        "%cd /content\n",
        "# Clone the repository\n",
        "!GIT_LFS_SKIP_SMUDGE=1 git clone -b dev https://github.com/camenduru/DynamiCrafter-576x1024-hf /content/DynamiCrafter-hf\n",
        "%cd /content/DynamiCrafter-hf\n",
        "\n",
        "# Fix for missing prompt file\n",
        "!mkdir -p prompts/1024\n",
        "!echo \"\" > prompts/1024/firework03.png\n",
        "\n",
        "# 2. INSTALL DEPENDENCIES\n",
        "# Pin open-clip-torch to 2.20.0 to prevent runtime crash\n",
        "!pip install -q xformers gradio omegaconf einops pytorch_lightning kornia open-clip-torch==2.20.0 timm av decord huggingface_hub\n",
        "\n",
        "# 3. DOWNLOAD MODEL (Multi-Mirror Retry)\n",
        "print(\"Downloading model checkpoint...\")\n",
        "target_dir = \"/content/DynamiCrafter-hf/checkpoints/dynamicrafter_1024_v1\"\n",
        "target_file = \"model.ckpt\"\n",
        "target_path = os.path.join(target_dir, target_file)\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "# List of mirrors to try\n",
        "mirrors = [\n",
        "    \"https://huggingface.co/Doubiiu/DynamiCrafter/resolve/main/checkpoints/dynamicrafter_1024_v1/model.ckpt\",\n",
        "    \"https://huggingface.co/camenduru/DynamiCrafter/resolve/main/dynamicrafter_1024_v1.ckpt\",\n",
        "    \"https://huggingface.co/vdo/DynamiCrafter/resolve/main/dynamicrafter_1024_v1.ckpt\",\n",
        "    \"https://huggingface.co/checkpoints/DynamiCrafter/resolve/main/model.ckpt\"\n",
        "]\n",
        "\n",
        "download_success = False\n",
        "for url in mirrors:\n",
        "    print(f\"Attempting download from: {url}\")\n",
        "    try:\n",
        "        # Using wget with -O to force filename and -c for resume if possible\n",
        "        result = subprocess.run([\"wget\", \"-c\", \"-O\", target_path, url], capture_output=True)\n",
        "\n",
        "        # Verify file size (should be > 1GB)\n",
        "        if os.path.exists(target_path) and os.path.getsize(target_path) > 1024 * 1024 * 100:\n",
        "            print(\"Download successful!\")\n",
        "            download_success = True\n",
        "            break\n",
        "        else:\n",
        "            print(\"Download failed or file too small. Trying next mirror...\")\n",
        "            if os.path.exists(target_path):\n",
        "                os.remove(target_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading from {url}: {e}\")\n",
        "\n",
        "if not download_success:\n",
        "    print(\"CRITICAL ERROR: Could not download model from any mirror. Please check internet connection or HF availability.\")\n",
        "    # We don't exit here to allow debugging, but app will likely fail\n",
        "\n",
        "# 4. APPLY PATCHES\n",
        "print(\"Patching app.py...\")\n",
        "with open('app.py', 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "# A. Enable Public Share\n",
        "content = content.replace('share=False', 'share=True')\n",
        "\n",
        "# B. Fix Black Video (Float32 VAE)\n",
        "# Define the patch code to inject at the TOP of app.py\n",
        "global_patch = \"\"\"\n",
        "import torch\n",
        "import types\n",
        "\n",
        "def patched_vae_decode(self, z, **kwargs):\n",
        "    # Force VAE decoding to use Float32 and disable autocast to prevent black frames\n",
        "    with torch.cuda.amp.autocast(enabled=False):\n",
        "        z = z.to(torch.float32)\n",
        "        return self._original_decode(z, **kwargs)\n",
        "\"\"\"\n",
        "\n",
        "# Prepend patch imports\n",
        "content = global_patch + \"\\n\" + content\n",
        "\n",
        "# Inject the application logic\n",
        "# We look for the model.cuda() call\n",
        "match = re.search(r'^(\\s*)model\\s*=\\s*model\\.cuda\\(\\)', content, re.MULTILINE)\n",
        "\n",
        "if match:\n",
        "    indent = match.group(1)\n",
        "    # Create the indented block using the detected indentation\n",
        "    patch_logic = f\"\"\"{indent}model = model.cuda()\n",
        "{indent}print(\"Applying VAE Patch (Float32)...\")\n",
        "{indent}model.first_stage_model.to(torch.float32)\n",
        "{indent}if not hasattr(model.first_stage_model, '_original_decode'):\n",
        "{indent}    model.first_stage_model._original_decode = model.first_stage_model.decode\n",
        "{indent}    model.first_stage_model.decode = types.MethodType(patched_vae_decode, model.first_stage_model)\n",
        "\"\"\"\n",
        "    content = content.replace(match.group(0), patch_logic)\n",
        "    print(\"VAE Patch injected successfully.\")\n",
        "else:\n",
        "    print(\"WARNING: Could not find 'model = model.cuda()' to inject patch.\")\n",
        "\n",
        "# Suppress warnings\n",
        "content = \"import warnings\\nwarnings.filterwarnings('ignore')\\n\" + content\n",
        "\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"Starting application...\")\n",
        "!python app.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}